{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e387b1d0-ff70-4d4c-8a30-d824880ab1c2",
   "metadata": {},
   "source": [
    "<h1>Agentic RAG</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c54dc55-60ba-42ee-b358-3a8201cfec57",
   "metadata": {},
   "source": [
    "<h2>Setup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2b3dc69-c7c4-4c7e-a3be-4e168455b319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aea288d0-f76a-4b06-84f3-255f2f3764a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe28bbf5-ee16-4712-863a-d23f4f35a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0230ae5-05ce-45d3-83d7-96b3e615b024-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "response = llm.invoke(\"Hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7013593-34a5-442a-a6e4-4ee3dd0c5ecd",
   "metadata": {},
   "source": [
    "<h2>Retriever</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b767aec5-4de9-4de7-b198-374704e77d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls] #Load documents\n",
    "docs_list = [item for sublist in docs for item in sublist] #Flatten the list\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a422717d-8464-4e45-9bbd-cd6e66473b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "question = \"agent memory\"\n",
    "documents = retriever.invoke(question) #the default number of retrieved documents (k) is 4, return a list of documents\n",
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a100ba78-d35c-4cf3-bd49-bc790725070a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "70869e75-9fa7-4a8b-9e1b-0a4aac1366c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bef4d9-5504-4b9b-94f8-2759e4589d24",
   "metadata": {},
   "source": [
    "Then we create a retriever tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8071e278-f8e9-4820-8a74-eabeedb8465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"retrieve_blog_posts\",\n",
    "    description=\"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3340a6f-8a6d-4747-93cc-deaadc03ea2f",
   "metadata": {},
   "source": [
    "<h2>Grader</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73fc937d-4b5e-4a3a-ae6c-bed219f606b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: int = Field(\n",
    "        description=\"Documents are relevant to the question, 0 or 1\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\n",
    "You are a grader assessing relevance of a retrieved document to a user question. \n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "Give a binary score 0 or 1 score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "human_msg = \"\"\"\n",
    "    Retrieved documents: \n",
    "    {documents} \n",
    "    \n",
    "    User question: \n",
    "    {question}\"\"\" \n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", human_msg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d331724-383f-4a6b-a93d-83f37e6991d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You are a grader assessing relevance of a retrieved document to a user question. \n",
      "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
      "Give a binary score 0 or 1 score to indicate whether the document is relevant to the question.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "    Retrieved documents: \n",
      "    \u001b[33;1m\u001b[1;3m{documents}\u001b[0m \n",
      "    \n",
      "    User question: \n",
      "    \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "grade_prompt.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9bf80eb5-5666-4283-9c42-ce1275dfc9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.GradeDocuments"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "score = retrieval_grader.invoke({\"question\": question, \"documents\": docs}) #We can pass a list of documents, a single document or a string\n",
    "type(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "784a7f63-30c0-468e-a378-7d1e6bb5032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.binary_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d0094-29ea-4683-be6d-213afa88d99a",
   "metadata": {},
   "source": [
    "<h2>Generate Answer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5bad2c2f-7083-45ce-88bf-b59e42b9d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\") #prompt has context and question parameter\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f7cff63-d79f-463a-a1ca-aab21bb78977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "06b53dbc-949a-466f-8de0-9cd424850f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In an LLM-powered autonomous agent system, memory is divided into short-term and long-term components. Short-term memory involves in-context learning, while long-term memory allows the agent to retain and recall information over extended periods, often using an external vector store for fast retrieval. This memory system enhances the agent's ability to handle complex tasks and improve over time.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbdb59a-c8d0-4a6e-8070-88af682e6fae",
   "metadata": {},
   "source": [
    "<h2>Question Re-writer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7173c83c-af0a-4a6e-b376-a2f0a157718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"\n",
    "You a question re-writer that converts an input question to a better version that is optimized for web search. \n",
    "Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "human_msg = \"\"\"\n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "    \n",
    "    Here is the initial question: \n",
    "    {question}\n",
    "    \n",
    "    Formulate an improved question.\"\"\" \n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", human_msg)\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "427ea34b-b88c-4a97-a1a4-6af37d56853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You a question re-writer that converts an input question to a better version that is optimized for web search. \n",
      "Look at the input and try to reason about the underlying semantic intent / meaning.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "    Look at the input and try to reason about the underlying semantic intent / meaning.\n",
      "    \n",
      "    Here is the initial question: \n",
      "    \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "    \n",
      "    Formulate an improved question.\n"
     ]
    }
   ],
   "source": [
    "re_write_prompt.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af7005ed-21b9-4789-9a6b-69718d9a7b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is agent memory and how does it function in artificial intelligence systems?\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "better_question = question_rewriter.invoke({\"question\": question})\n",
    "print(better_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed73b6-31e1-4930-9e7a-35cf81c3541e",
   "metadata": {},
   "source": [
    "<h2>Graph State</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d729e134-d859-43bb-a96f-4d9c0400771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState \n",
    "\n",
    "class State(MessagesState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd10953a-d44a-450c-8075-ba8ada1f7446",
   "metadata": {},
   "source": [
    "<h2>Assistant Node</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4d70070a-eb06-426e-938a-7b5644fe7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL ASSISTANT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80746215-5252-4429-abea-2fdb68347afb",
   "metadata": {},
   "source": [
    "<h2>Generate Node</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "05474acb-194b-424d-a7c0-a0362b53c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    context = messages[-1].content\n",
    "\n",
    "    # RAG generation\n",
    "    generation  = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    return {\"messages\": [generation]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29b895-146d-4a25-b8b9-7306c3f9737a",
   "metadata": {},
   "source": [
    "<h2>Question Re-writer Node</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "008c54b4-5048-44d0-aa30-59c2950114f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---Rewrite---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    \n",
    "    return {\"messages\": [better_question]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b5a14c-7305-468f-a766-ab9b89ee8476",
   "metadata": {},
   "source": [
    "<h2>Conditional Edge</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f1f7c00-88db-42a1-ad20-e00549589633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def decide_to_generate(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or rewrite a question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    context = messages[-1].content\n",
    "    print(f\"question: {question}\")\n",
    "    print(f\"context: {context}\")\n",
    "\n",
    "    score = retrieval_grader.invoke({\"question\": question, \"documents\": context})\n",
    "    grade = score.binary_score \n",
    "    print(f\"grade: {grade}\")\n",
    "    if grade == 1:\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f14a6-f08c-4189-869a-afb0828a2367",
   "metadata": {},
   "source": [
    "<h2>Compile Graph</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c65943bb-598b-41ee-a410-9c5e09bbe2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"assistant\", assistant)  # assistant\n",
    "workflow.add_node(\"retrieve\", ToolNode(tools))  # retrieve\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"rewrite\", rewrite)  # rewrite\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"assistant\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        \"rewrite\": \"rewrite\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"rewrite\", \"assistant\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e5916810-4419-4798-9e03-189f7894bdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL ASSISTANT---\n",
      "\"Output from node 'assistant':\"\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zYShV8dQiUhA6NgcW9RYpqqG', 'function': {'arguments': '{\"query\":\"types of agent memory\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 89, 'total_tokens': 108, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5c7c46f2-b791-4d9e-ab75-ee367b23cf6b-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'types of agent memory'}, 'id': 'call_zYShV8dQiUhA6NgcW9RYpqqG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 89, 'output_tokens': 19, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "---CHECK RELEVANCE---\n",
      "question: What does Lilian Weng say about the types of agent memory?\n",
      "context: Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "grade: 0\n",
      "---DECISION: DOCS NOT RELEVANT---\n",
      "\"Output from node 'retrieve':\"\n",
      "{ 'messages': [ ToolMessage(content='Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.', name='retrieve_blog_posts', id='bf0d67b2-b1bb-4d7d-8638-bd09c14c4be4', tool_call_id='call_zYShV8dQiUhA6NgcW9RYpqqG')]}\n",
      "---Rewrite---\n",
      "\"Output from node 'rewrite':\"\n",
      "{ 'messages': [ 'What insights does Lilian Weng provide on the different types '\n",
      "                'of agent memory?']}\n",
      "---CALL ASSISTANT---\n",
      "\"Output from node 'assistant':\"\n",
      "{ 'messages': [ AIMessage(content='Lilian Weng discusses two main types of agent memory:\\n\\n1. **Short-term Memory**: This is associated with in-context learning, where the model utilizes its short-term memory to learn and adapt based on the immediate context provided in the input. This type of memory is transient and is used to process and respond to the current task or query.\\n\\n2. **Long-term Memory**: This type of memory allows the agent to retain and recall information over extended periods. It often involves leveraging an external vector store and fast retrieval mechanisms to store and access a potentially infinite amount of information. This enables the agent to remember past interactions or data that are not part of its immediate context.\\n\\nAdditionally, Weng mentions the use of external tools or APIs as a form of memory extension. This allows the agent to access information that is not embedded within its model weights, such as current data, code execution capabilities, and proprietary information sources. This tool use is crucial for accessing dynamic or external information that the model itself cannot store or process internally.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 208, 'prompt_tokens': 568, 'total_tokens': 776, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-e83f1acb-a6d0-4688-aa6f-4b4a38a6dd30-0', usage_metadata={'input_tokens': 568, 'output_tokens': 208, 'total_tokens': 776, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What does Lilian Weng say about the types of agent memory?\")]}\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "24dfb22f-91c3-452d-a78a-85e81146e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lilian Weng discusses two main types of agent memory:\n",
      "\n",
      "1. **Short-term Memory**: This is associated with in-context learning, where the model utilizes its short-term memory to learn and adapt based on the immediate context provided in the input. This type of memory is transient and is used to process and respond to the current task or query.\n",
      "\n",
      "2. **Long-term Memory**: This type of memory allows the agent to retain and recall information over extended periods. It often involves leveraging an external vector store and fast retrieval mechanisms to store and access a potentially infinite amount of information. This enables the agent to remember past interactions or data that are not part of its immediate context.\n",
      "\n",
      "Additionally, Weng mentions the use of external tools or APIs as a form of memory extension. This allows the agent to access information that is not embedded within its model weights, such as current data, code execution capabilities, and proprietary information sources. This tool use is crucial for accessing dynamic or external information that the model itself cannot store or process internally.\n"
     ]
    }
   ],
   "source": [
    "# Final generation\n",
    "print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "71835c1f-353d-4622-aa02-233718a21c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL ASSISTANT---\n",
      "\"Output from node 'assistant':\"\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_7cklSUCNTh6G9XwMwDQk8tn2', 'function': {'arguments': '{\"query\":\"Prompt Engineering\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 87, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-22d90b5c-5a0e-4e94-8bb4-965cf4d64555-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'Prompt Engineering'}, 'id': 'call_7cklSUCNTh6G9XwMwDQk8tn2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 17, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "---CHECK RELEVANCE---\n",
      "question: What does Lilian Weng say about the Prompt Engineering?\n",
      "context: Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
      "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
      "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\n",
      "Basic Prompting#\n",
      "\n",
      "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
      "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
      "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\n",
      "Basic Prompting#\n",
      "\n",
      "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
      "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
      "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\n",
      "Basic Prompting#\n",
      "\n",
      "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
      "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\n",
      "[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\n",
      "Basic Prompting#\n",
      "grade: 1\n",
      "---DECISION: DOCS RELEVANT---\n",
      "\"Output from node 'retrieve':\"\n",
      "{ 'messages': [ ToolMessage(content='Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\n\\nPrompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\n\\nPrompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\n\\nPrompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#', name='retrieve_blog_posts', id='2db33711-f95d-42fb-8c7f-55fb58d1b8ae', tool_call_id='call_7cklSUCNTh6G9XwMwDQk8tn2')]}\n",
      "---GENERATE---\n",
      "\"Output from node 'generate':\"\n",
      "{ 'messages': [ 'Lilian Weng suggests that some prompt engineering papers are '\n",
      "                'unnecessarily long, as the techniques can often be summarized '\n",
      "                'in a few sentences, with the rest focused on benchmarking. '\n",
      "                'She believes that a shared benchmark infrastructure would be '\n",
      "                'more beneficial to the community. Additionally, she notes '\n",
      "                'that setting up iterative prompting or external tool use is '\n",
      "                'not trivial, nor is aligning the research community to adopt '\n",
      "                'such methods.']}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"What does Lilian Weng say about the Prompt Engineering?\")]}\n",
    "\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3dde2c1-b45e-4dfb-b1b7-d309379b5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lilian Weng suggests that some prompt engineering papers are unnecessarily long, as the techniques can often be summarized in a few sentences, with the rest focused on benchmarking. She believes that a shared benchmark infrastructure would be more beneficial to the community. Additionally, she notes that setting up iterative prompting or external tool use is not trivial, nor is aligning the research community to adopt such methods.\n"
     ]
    }
   ],
   "source": [
    "# Final generation\n",
    "print(value[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e16b47a6-65db-46d4-8e39-1c1e0eac4f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL ASSISTANT---\n",
      "\"Output from node 'assistant':\"\n",
      "{ 'messages': [ AIMessage(content='An autonomous agent is a system that operates independently to perform tasks or make decisions without human intervention. These agents are designed to perceive their environment, process information, and take actions to achieve specific goals. They can adapt to changes in their environment and learn from experiences to improve their performance over time.\\n\\nAutonomous agents are used in various fields, including robotics, artificial intelligence, and software applications. In the context of AI, they often involve complex algorithms and models, such as reinforcement learning, to enable decision-making and problem-solving capabilities. These agents can be found in applications ranging from self-driving cars and drones to virtual assistants and automated trading systems.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 129, 'prompt_tokens': 81, 'total_tokens': 210, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_eb9dce56a8', 'finish_reason': 'stop', 'logprobs': None}, id='run-49deca3f-e3eb-4d57-af61-15be74312296-0', usage_metadata={'input_tokens': 81, 'output_tokens': 129, 'total_tokens': 210, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"What is a Autonomous Agent?\")]}\n",
    "\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8482ad8d-77e6-4e4a-9faa-10900c16cbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An autonomous agent is a system that operates independently to perform tasks or make decisions without human intervention. These agents are designed to perceive their environment, process information, and take actions to achieve specific goals. They can adapt to changes in their environment and learn from experiences to improve their performance over time.\n",
      "\n",
      "Autonomous agents are used in various fields, including robotics, artificial intelligence, and software applications. In the context of AI, they often involve complex algorithms and models, such as reinforcement learning, to enable decision-making and problem-solving capabilities. These agents can be found in applications ranging from self-driving cars and drones to virtual assistants and automated trading systems.\n"
     ]
    }
   ],
   "source": [
    "# Final generation\n",
    "print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b65cb1-2add-4fcf-bbcc-ba3638e0dbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
