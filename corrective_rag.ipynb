{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21de7e84-91ea-4da6-a2e6-c62a5389af72",
   "metadata": {},
   "source": [
    "<h1>Corrective RAG (CRAG)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce642f-f929-4699-9d35-448e32b746bd",
   "metadata": {},
   "source": [
    "<h2>Setup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfe4136-05cb-4b29-9c7e-2400cfb79bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902b1ced-33a3-4d57-adf1-f88eb585c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530d4a8f-4143-44af-b6e2-52d67a84a7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-f35fcbe3-4da4-409b-865c-8066c554afeb-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "response = llm.invoke(\"Hi\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e9b4c-4656-483b-83ed-d5ac8c3c7044",
   "metadata": {},
   "source": [
    "<h2>Retriever</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d501b430-6004-4680-8508-5fa61c712061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls] #Load documents\n",
    "docs_list = [item for sublist in docs for item in sublist] #Flatten the list\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83afdbf5-d1b1-4f97-bef4-507de0489d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "question = \"agent memory\"\n",
    "documents = retriever.invoke(question) #the default number of retrieved documents (k) is 4, return a list of documents\n",
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc80d562-7ab0-460c-9eb2-95bd96ae358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6b9faf-1892-4a8d-9d56-63651e0722fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747ebeae-0a69-4964-a337-0490e8ff9fd8",
   "metadata": {},
   "source": [
    "<h2>Grader</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fbb49cf-c454-488f-a7c2-8fe6198bda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: int = Field(\n",
    "        description=\"Documents are relevant to the question, 0 or 1\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\n",
    "You are a grader assessing relevance of a retrieved document to a user question. \n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "Give a binary score 0 or 1 score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "human_msg = \"\"\"\n",
    "    Retrieved documents: \n",
    "    {documents} \n",
    "    \n",
    "    User question: \n",
    "    {question}\"\"\" \n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", human_msg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "045d13e3-2abc-4935-99e9-0d7307db65f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You are a grader assessing relevance of a retrieved document to a user question. \n",
      "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
      "Give a binary score 0 or 1 score to indicate whether the document is relevant to the question.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "    Retrieved documents: \n",
      "    \u001b[33;1m\u001b[1;3m{documents}\u001b[0m \n",
      "    \n",
      "    User question: \n",
      "    \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "grade_prompt.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99a0cb8-ec60-4c7c-aac7-354f44a770d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.GradeDocuments"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "score = retrieval_grader.invoke({\"question\": question, \"documents\": documents}) #We can pass a list of documents, a single document or a string\n",
    "type(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ef995a-cdc3-4240-9019-01414f7152dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.binary_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f27798-c00c-4252-aa8c-62e6d0638667",
   "metadata": {},
   "source": [
    "<h2>Generate Answer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff9e2ab-ea62-4212-ac0b-dbcbc6cee337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\") #prompt has context and question parameter\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9afcea6-fab2-4e8a-86ff-7a65a10e6273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe83d648-7e12-4ab9-b4c5-9dbea934bf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In an LLM-powered autonomous agent system, memory is divided into short-term and long-term components. Short-term memory involves in-context learning, while long-term memory allows the agent to retain and recall information over extended periods, often using an external vector store for fast retrieval. This memory system enables the agent to learn from past experiences and improve future actions.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edef52c-cc2a-4b0c-9f41-dfac5205fd0d",
   "metadata": {},
   "source": [
    "<h2>Question Re-writer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1853cf0-f661-415b-bf53-36602eea16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"\n",
    "You a question re-writer that converts an input question to a better version that is optimized for web search. \n",
    "Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "human_msg = \"\"\"\n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "    \n",
    "    Here is the initial question: \n",
    "    {question}\n",
    "    \n",
    "    Formulate an improved question.\"\"\" \n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", human_msg)\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c37a9e-1608-4df7-a3b4-3a521c1d80e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You a question re-writer that converts an input question to a better version that is optimized for web search. \n",
      "Look at the input and try to reason about the underlying semantic intent / meaning.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "    Look at the input and try to reason about the underlying semantic intent / meaning.\n",
      "    \n",
      "    Here is the initial question: \n",
      "    \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "    \n",
      "    Formulate an improved question.\n"
     ]
    }
   ],
   "source": [
    "re_write_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "493d3690-1c45-4fd7-8a9d-59a31c80eb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is agent memory and how does it function in artificial intelligence systems?\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "better_question = question_rewriter.invoke({\"question\": question})\n",
    "print(better_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345cc64-a427-4e6f-b97f-382012a15d42",
   "metadata": {},
   "source": [
    "<h2>Web Search Tool</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "301cfab3-0e64-4f80-8e54-129c9ca7612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c2c979-475c-4b15-827d-4791ddfa3454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "docs = web_search_tool.invoke(better_question) #return a list of dict\n",
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ef76ed0-e0a0-468a-a0e5-177bd5fe13c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fce489e-03f0-4257-965d-46f873d35b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Agent Memory encompasses techniques that allow AI systems to maintain and use information across interactions. It includes short-term memory via context\n"
     ]
    }
   ],
   "source": [
    "print(docs[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bd85f-943e-48ee-8c11-b3688630f8b0",
   "metadata": {},
   "source": [
    "<h2>Graph State</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca6aa82f-a40a-4eef-976c-e9fa76addc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.schema import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: bool\n",
    "    documents: List[Document]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece59afb-54a4-48d2-b8b2-8cd8117ec35c",
   "metadata": {},
   "source": [
    "<h2>Retriever Node</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1efa1888-4925-4fc8-9836-a76a0afbdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    \n",
    "    return {\"documents\": documents}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b931f4-afae-4de7-9070-5c629c69798a",
   "metadata": {},
   "source": [
    "<h2>Grader Node</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82379513-fc88-46a7-9bed-9889533a8492",
   "metadata": {},
   "source": [
    "If any docs are relevant, we can proceed with generating answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82742eaf-97fc-4bab-ad07-ec1d70491841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = True\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"documents\": doc}\n",
    "        )\n",
    "        grade = score.binary_score \n",
    "        if grade == 1:\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(doc)\n",
    "            web_search = False\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            \n",
    "    return {\"documents\": filtered_docs, \"web_search\": web_search}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d7caf-8987-4aaa-859d-2210aab0ae00",
   "metadata": {},
   "source": [
    "<h2>Generate Node</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "356769f1-ec86-45dc-8c30-6113de1c5b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    \n",
    "    return {\"generation\": generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16eec5-956c-4f0b-98df-d46aed92d65e",
   "metadata": {},
   "source": [
    "<h2>Question Re-writer Node</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0dae5ca9-52d7-495b-88de-b86991e45bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---Rewrite---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    \n",
    "    return {\"question\": better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19aa5d-4626-41e9-965d-d63d383ffc04",
   "metadata": {},
   "source": [
    "<h2>Web Search Node</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ad70d4b-8c44-41da-8336-565ab62ce1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke(question)\n",
    "    web_results = \"\\n\".join([doc[\"content\"] for doc in docs])\n",
    "    documents.append(Document(page_content=web_results))\n",
    "\n",
    "    return {\"documents\": documents}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b70f1-1634-4e54-b99b-71d843fd6d65",
   "metadata": {},
   "source": [
    "<h2>Conditional Edge</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d3fc7423-9a0d-4f5b-bf1f-70ec937ef30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def decide_to_generate(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or rewrite a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    web_search = state[\"web_search\"]\n",
    "\n",
    "    if web_search:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUESTION---\"\n",
    "        )\n",
    "        return \"rewrite\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415902b-8e80-4d91-af58-ec24b59ec9eb",
   "metadata": {},
   "source": [
    "<h2>Compile Graph</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f73c1463-6caf-44c9-af9a-5a83bb3cf2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAAJ2CAIAAAAGwS0CAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcU9f7x5+bDUkgkLDDFAQRRHCDizqqOLFucbRSax21tba1Squ1rjqqdVXraFWcOLBalWotVVGpAxUcKKLslUAIKzu/P26/lF9FIOEm995w3y//CDfnnPvcfHzOc+655z4H0ev1QEEGaHgbQNFSKKlIAyUVaaCkIg2UVKSBkoo0MPA2oEXUVukqSpQ1lZoauVar0Ws1JLjBoNGBwaRxbejWNgw7RxbXlt7KBhEi31dVStRZ96uzM2r0emAyEa4tw9qGzrVhaNQ6vE1rHgYDqa3W1lRqa+QanVav1ei9g7i+nfl2jkzjGiSoVIpa3c2zkroarZ0jyzuI6+zFwdui1lKaq8zOqJaVqRlMJHyEyJpvsJMRUaq0P2V3LpeHDxd17GWDty3Y8/TvqpSzktD+dmEDBAZVJJxUF34ucm1nFdLXsMsgHenXK189qRnxvmvLqxBrBJiwKa99GN/idQKA4N62wRGCg6tyWl6FQF51aG1un9EijwBrvA0xH8WvFEkHiqd/7dWSwkSRKml/sU8nnl8oD29DzM3LRzWPbsqHx7o0W5IQUj34qxJAH9LP8vu9Rkm/XqlW6cPeauby8Y9VapX+5nlJm9UJjVv3/ihX1DRzs4i/VDfOSiJGiPC2AmfCR4hunJU0XQZnqaplmmqZJri3rXlOl5GRoVQq8areBIE9bZQKXaVE3UQZnKXKTq/h25lpHvLs2bMzZsyoq6vDpXqz2NgzXjysbqIA3lJlVHsHmWnUZ7RDoCMvE/lTPT5BvJcZNU0UwHNmXaPSqxQ69/ZWmLesUCjWrl179epVAAgNDV20aNGdO3fWrl0LAAMHDgSAZcuWjRgxoqSkZMeOHSkpKdXV1Z6enu++++6QIUMAQCaTDRw4cMGCBZmZmcnJyQEBAaNGjXq9OrY2u/hwAEBRo+NwG/cfPKWSSdRatUluFX7++edz587Nnj1bJBKdO3fOysoqIiIiJiYmPj5+8+bNPB7Pw8MDADQazaNHj8aOHSsQCK5cuRIXF+fu7t6xY0e0kb17944bN27nzp10Ot3Jyen16pij1eorpWoOl93ot3hKVVOp4dqaxIDCwkIrK6sZM2YwGIzRo0ejB8ViMQAEBQUJBP/cGLi5uSUkJCAIAgCjRo0aOHBgcnJyvVTBwcFz586tb/P16pjDs2HUVGoAGpcKz1hVK9dwbUwi1dChQxUKxfz587Oyspou+ezZs4ULFw4ZMiQ6Olqr1Uql0vqvunfvbgrbmsDallEj17zpWzyl0gPCZJvEgPDw8B9++EEqlU6cOHHlypUaTePXf/v27enTp6tUqmXLlq1bt87W1lan+/c+1MoK+yDaNEwWDd4cEPDsAK15NLlUZaLGw8PDe/bseeTIkU2bNrm4uMycORM93nAibc+ePWKxePPmzQwGo4XamHQeTl6udvJsvPfD2ausbRg1cq0pWlapVABAo9GmTJni4ODw9OnTeiXKysrqi8lksvbt26M6qVSq2trahl71H16vjjlNRwQ8vYpvx+TyTWLA0aNH//rrr6ioqLKysrKyssDAQAAICQmh0+kbNmwYOXKkUql85513unbtevbs2TNnztja2h46dEgul7948eJNfvN6dczN5nDpfMEbfxA8vcqKR6ur0ZTkKDBvWSwWq1SqTZs2JSYmTpw4cerUqejBpUuX5uTkbNiw4dKlSwDw4Ycf9urVa/369evWrevRo8d3330nkUju3Lnzpjb/Ux1bJAWqqnI1781zNzg/BLlzqUKj1vWMEuJoA0G4/Xu5VqNv4qfAeR2gd0fencvlTRSora2Niopq9CuxWJyfn//68X79+n3zzTfY2dg427ZtO3HixOvH2Wx2o1NQnp6e+/fvb6JBWak6pK9dEwXwf7R44eei9mH8diGNzwTqdLri4uJGv0KQxo23srKys2vqmjGhsrKypqaRKTuVSsVisV4/zmAwHB0d39Taq8e16SmyplfF4L+6NnyE6MzOwjdJRaPRXF0NWNZjNmxtbW1tMXt2c+OsZMh056bL4P9o0VbEbB/Kf3avqfl/yyb7YY1nINfeuRFfbAj+UgFAz2H2aX9WlOWb9ikDMakoUd08L4kY0fzAihBSAcCET90TNufptPivyTEzh9flTvrcs0VF9YRBq9HtjssuL1HhbYiZkEvVu5e80Kh0LSyP/wiwITodHF6b03u0g1eghS/czHtWe+Vo6eQvPFo+YU0sqVCuniyTFCrDR4gs4AWQ1ynNU944KxE4svqPdTCoIhGlAoDCF3U3zkkd3dlOnhyfIB6TjeBtUWvRqPUvM2pKchUFWXURI0Riw5cpEFQqlFePa5/dq3qZXu3Vkcvh0rk2DGs+3YpL1+qIa3M9NDpNUa2prdLWyDWqOl3Ww2qfjly/ML5PMNe4BgktVT35z+vKi1W1VZpauRYAlAqM31pMTU3t3r07+uQeK1hsBEEQaxu6NZ9h58Rq/Wofckhlanr06JGSkoI+uCIsRLmvomgWSirSQEkF6DoybAOVKaCkAgBIT08nfsympAIAsLOzo7yKHFRUVFBeRQ7EYjHlVeQgPz+f8ipyEBoaSnkVOUhLS6O8igIzKKkAAIRCIdUBkgOpVEp1gOTA2dmZ8ipyUFxcTHkVBWZQUgEAdOjQgeoAycGTJ0+oDpACMyipAH15lOoAycGDBw+oDpACMyipgJpZJxPUzDoFllBSAbW4jExQi8sosISSCqh1gGSCWgdIGqiZddJAzaxTYAklFaCpoakOkBwUFBRQHSA5oJ5XkQbqeRVp6Ny5M+VV5OD+/fuUV5EDLy8v4ntVm04xMnToUCaTiSa6FwqFNBpNp9N5eHjs2LEDb9MagdD5T0xNSUkJjfZPv4ImM7axsZk2bRredjVOm+4Aw8PD/3PE39+/Z8+eOJnTDG1aqhkzZtjY2NT/SWSXautSde3aNSAgAI3Wer0+ICCgV69eeBv1Rtq0VAAwc+ZMkUiE5k2fMmUK3uY0RVuXqkuXLgEBAQAQEBAQERGBtzlNQawRoLJOJylQ1dW8cRM7UzA8MlZWwBkeOSHrgVnT8nOs6CIxm2NNwjTDSQdKcp7UuPlakyHdKQYwGEj+sxqPAO7gqU4tuf8mhFQatf7klvzg3vbuAUbmdSUvBc9r0/6Ujv1I3GwqZUJIdfz7vG5DHEVub9xm0LKpKFFdTyye/Hkzew3jP6x4nlYtcrNqszoBgJ0Ty60d9+ntqqaL4S9VWYGSw6XjbQXOcLj0ZnevwV8qZa3ORtTMfkAWj42QpaxrJiM5AaSq02k1GOdNJx06rV5Z28y+u/hLRdFCKKlIAyUVaaCkIg2UVKSBkoo0UFKRBkoq0kBJRRooqUgDJRVpsHyptFptevr9pstoNJqYadE/7txsLqOMwfKlWr/x2+83r266DIIgfL4Nh0PobYiJtQzGCPR6fdNvBqiUzTwH0uv1dDr9x+37sTYNY8jnVZWVssgBXY8dP7hyddzQYb0XfPI+evzMryemTB399tDw6e+OPXBwj1KpBIC165b/mXzp1avsyAFdIwd0LSouBIAftnw3ZuzgGzeuxkyLjhzQ9fIfF9Bv9+77962C11tTKpUjR7+1anVcfZn79+9GDuh669Z1ACgqLvzq60VRw/uMHjPw8y/mPc18jPmFk9Wr4uP3jho1buOGnXQ6HQB+2f9Twon4MdETPT198vJeHTt+IL8gd8niFTGT3ysrLSkqKvhy8QoAENqL0Oo1NdV7f97x8YLFCkVdl7Ae367Y8M2KxfWNv6m1wYOG/Xb+dG1trbW1NQBcunzeycm5e/dwqVQy/6P33Nzc581dhCDI77//tuDj2L17jond3DG8ZLJKFRgYHDtzLvpZIik7dHhf3NJV/foOQI8IhQ6bNq+ZN3eRWOxhaysor5AGB3duWF2lUi1aGNehQxD6Z++I/vW9aBOtjRg+5uSpI9euXXn77eFKpfLqtT8mjJ9Go9EOxu+xE9hvXP8jurPwoIFRMdNGJydfipnyHoaXTFapwsK613++ezdVo9GsWh1X3zuhy7AkZaU2fJtGq3M4nHqd/kMTrfn4+AYHd778x4W33x6ecuMvhUIRNXQUAKSmppSWlUQN71PfiFqtrpCVY3rFpJWKw/l3n3FpuQQAVq/a7Ojg1LCMq6v4TdWtrKzf9FXTrY0YNmbtuuVSqeTS5fO9I/rb2wsBoLxC2qtXn1mx8xuWt7UVGHtxjUNWqRrC/5/reHh4NVrAoLWOTbfWt++Ards3nDp99Pbtm+vXba+vUlkpe9PZsYJ8I8DXCQ3thiDI6cRj9Ufq6urqP3M4VuXlUp2upSttmm6NzWYPGhR15Oh+Nzf30M5d0YNhYd0zMh5kPnvSaBWssASpxG7uY6In3rhxdUncJ+cvnDkYvzdm2uhnz5+i34Z0Cquqkn+/aXVS0rkbN662sjW0D9Tr9SOGj6k/Mn3aLD7f5rPP58Yf2vfb+cRlyz9ftSbuDc0bjyV0gAAwd85CR0en06eP3b59UygU9ekd6SByRL8aNCgq89nj3y/9dvPWtSFvjwgP79ua1gDAy8una5cegwcPrz/i5iretmXfj7s2Hzq8D0EQP7+A6NETML9G/NesX9xf4tLO2ieYj68Z+JL7pOZVhnxYrEsTZSyhA2wjUFKRBkoq0kBJRRooqUgDJRVpoKQiDZRUpIGSijRQUpEGSirSQElFGiipSAP+UnEFNDoNfzPwBUGAZ8dsugz+vxHfllmaj/0zU3JRlq/g2jSTZwV/qTwCuDUyNd5W4ExVhdqzwxtX5qDgL5W9M9Mz0PrqyRK8DcGN66dL3NpxHMTNZJnC/ykwypPUqsd/y72D+EJXDpNF9Oz0mKDR6CUFitwnNe06cYMjGl+v2BCiSAUAJa8Uj27Jqys1slJz94dVVXL+GxZ3mg6BE5PLZ3ToYePq06I3UAgkFY706NEjJSUFXcZMWPCPVRQthJKKNFBSAQCEhoYSf6cdSioAgLS0NOLHbEoqQPPhU15FDp4+fUp5FTkIDg6mvIocpKenU15FDvz9/SmvIgeZmZmUV1FgBiUVAECHDh2oDpAcPHnyhOoAKTCDkgoAwMrKiuoAyUFdXR3VAZIDe3t7yqvIQXl5OeVVFJhBSQUA4OnpSXWA5CAnJ4fqACkwg5IKACAwMJDqAMnB48ePqQ6QAjMoqYBaXEYmqMVlFFhCSQXU2goyQa2tIA3UzDppoGbWKbCEkgqohdBkgloITRpCQkIoryIHDx48oLyKHHTq1InyKnLw8OFDyqvIASliVZtOMTJo0CAGg4EgSFlZmZ2dHbrDpre3944dO1pQ29wQOv+JqZFKpbT/pSIsLy8HAGtr65EjR+JtV+O06Q4wNDT0P52Kj4/PkCFD8LOoKdq0VDExMXZ2dvV/crnc8ePH42pRU7RpqSIjI728/t3L0sPDIyoqCleLmqJNS4U6FpfLRV1qypQpeJvTFG1dqv79+6OO5eHhQdgohUKmEWClxCQpHSeMeXd70fbx0TNM0T4CYCNqJtVzS5si/n2VXKq58Zv0xYMqD39eebESb3MMw86ZnZdZ3S6Y13OYUODQKs2ILlVFiSbxx/y3JrkKHFi0ZrJbExS9DmRlqj+PFg1731XkYrxahJZKXq45+UP+2IWm3XDcbJzakjNilqu9k5FqEXpYces3aeQkV7ytwIwBE13/vlBudHVCS/XiYbUAo5hMBGwdmFkPqoyuTlypqsq1Yj9rOpPoE94GgIBXR155iZHjTOJKBaCXFpFsvNcsslIlAkYODogsFcX/g5KKNFBSkQZKKtJASUUaKKlIAyUVaaCkIg2UVKSBkoo0UFKRBkqqZli5Om7ajHfwtgIoqciEJUtVWSmTV8lfP07kB99NQKYVSy0hKencoSM/l5YWe3u1Q2g0ZyeXr79ak/zX5W9WLP72mw3HEg4+ffpo0sTpMVNmHji4+8qVpNKyEqFQNHjQsBnTP0BfLwCAK3/+vv/ATyUlRV6ePjqdrmH7Z349cTwhXiIpdXZ2HfDWkAnjp7LZzWy9jBUWJdX1lOS165YPHxbdo3vE8RPx6en35835tP7bH7Z+F/ve3Pfe/VDs5kGn0+/eTe0V3tfVRZyVlRl/aB+fbzN+XAwAXP7j4qrVcaGdu44fF1NcXHj4yC9ubu5oC7/s/ynhRPyY6Imenj55ea+OHT+QX5C7ZPEK81ydRUl15kyCl5fPpwuXAkBAQMdxE4beSr0eGBiMfhs9esLbbw+vL7xj+/76d6oKi/KvXrsyflyMUqnctn1Dp06h69dtR52soCAv68UzAJBIyg4d3he3dFW/vgPQWkKhw6bNaz779Csm0xyrCixKqtKyErHYA/0sEjlwOJyqBrEqLKx7w8IVFeUHDu6+fecWWobP4wNAesb9ykrZ2Hcm13eGtP99uHs3VaPRrFodt2p1HHoEjXl1ijpKKoNxdRVnZj5WqVQsFis7O0uhUPj6+td/a21lXf+5vFw6a/YUKyvr99790NVVvG/fjrz8HAAoLS0GAGfnRpZJScslALB61WZHB6eGx3lcnokv6x8sSqpJE6YvXDR74aLZXcK6X7p0PsA/8O3Bwxst+evZkxUV5du3/uLk5AwAjo7OqFQCWzsAkMkqXq9Sv8m9hwc+6xItarAeFBTyzphJOp2usDB/woRpmzftftO29HK5TCCwQ3UCgEq5DO3N2rVrT6PRLv9x4fUqoaHdEAQ5nXis/khdXZ3JLqURLMqrEk4cSku7PX78VARBGAxGfn5uu3Z+jZbs3Lnr6cTj+37+sWPHkGvXrqSmpuh0uspKmZOT89AhI387n6hSKrt3D5dKJamp1+3shAAgdnMfEz3x5KkjS+I+6R3RXyqVJJ45vmb1D+39AsxzdRYllX/7wIQTh+rDPgCMGD5m4SdLXi/Zt89b06bGnk48nph4vFd43+3bflmz9uvTicdmTP9g/rzPWCzW5T8u3rl7Kyioc7t27cvLpWituXMWOjo6nT597Pbtm0KhqE/vSAeRo9mujrhr1qvKNSe35r/zsWGBQavVooM3lUq1a/eWxMTjSRduvKkbND9ntucMm+li58Qyoi5RrgETfv/9tz37tkf2H+zi4lZRIb127YqXlw9xdGolFnIZKJ5ePsFBnS//cUEurxQKRRHh/WKmzMTbKMywKKn823f4Km413laYCosarFs2lFSkgZKKNFBSkQZKKtJASUUaKKlIAyUVaaCkIg2UVKSB0FIJXc20bsts2Dmzjc5nTFyp+PaMwqxatVLXgrLkQKeFV4+qBY6WmLjHN5RfUarC2wrMqChRtg+1Mbo6oaXqPUp0Ob4Qbysw43J8YcRIodHVifsUGKWuSvvzN68GTHKxEbF4AlI+sqmp1FSWqZKPF8Us8eLaGp8oj+hSAYBWo085I83OqLYVsUpzm1okpNPpEIRmtm0I9HrQ6XR0elM9k4M7Ry5Ve3fkho8QMtmt6sNIIFU9amVTpn7zzTfh4eGDBg0yo0Vw7dq1CxcurF7dxPNMfSsVqodMUjVBTU2NRqOxtbU1/6nlcjmNRuPxTL7GltDDihZSU1OTlZWFi04AYGNj8+rVq+rqalOfyBKkmj9/focOHXA0ICgoaM6cOaY+C+k7wNzcXHt7ezP0P01TW1tbWlracC8EzCG3VxUUFJgnTjSLtbU1k8nMzc013SlILNW9e/eWL18uFovxNuQf3NzcVq5ceffuXRO1T2Kp0tLSdu/ejbcV/48dO3bcv3/fRI2TPla1HUjpVfHx8Vu3bsXbijfy9ddfX758GfNmySdVSUmJRCKZP38+3oa8kRUrVly8eBHzZqkOkDSQzKsuX76ckpKCtxUt4vTp08XFxRg2SCapMjIyDh48GBERgbchLSIgIGDRokUYNkimDrD+jUSyUFhYaG1tLRAIMGmNNF6Vn59fWEiyJ8IuLi7/SdHUGsghlUQiiY2NdXd3x9sQw0AQ5KeffkpISMCkNXJIlZGRsW/fPrytMIa5c+diNX9BpljVxiGBV3355Zf5+fl4W2E81dXV165da307RJfq/PnzDAaDONPnRsDj8fbv35+WltbKdqgO0Bzk5OQUFBSEh4e3phFCS1VZWVldXe3m5oa3IYSA0B3g0qVL5fJG8gSTkcOHD//111+taYG4UhUUFAQFBeG7vgVD2rdvf/jw4da0QOgO0MLIy8tzdXU1em6MuF514sQJlcpyXgMBAHd399bMYRJUqrS0tIsXL7JYxiRjIyw3b95cs2aN0dUJKhUAYPsEgQiEhITk5OQYXZ2KVWaloqKCz+cbl6KQiF6lUqnWrVuHtxUmwdbW1qKGFQ8fPszOzsbbCpPw+++/x8XFtaBgIxBRKoFAQOQFSa0hODi4qKjIuLpUrCINRPSqrVu3Pn/+HG8rTEVFRYVarTaiIhGlunLlitk2hTI/P/zwg3ELOoko1fvvv2/Bs+kBAQElJSVGVKRiFWkgnFdVV1cvX74cbytMiF6vt5BYVV1dffv2bbytMCHV1dXGZWwgnFQ8Hu+jjz7C2woTwufzhUKhQqEwtCIVq0gDUbIWfffdd8eOHUNz5SHIP/+BdDpd6xf6EJDi4mKBQMDhcAyqRZQOcPLkyWKxGEGQhmr16NEDb7tMwrZt25KTkw2tRRSp3N3d+/Tp07A3trOzmzZtGq5GmQpfX1+NRmNoLQLFqoKCgjlz5hQUFKAj2q5du+7atQtvowgEUbwKzfsQERGB/tcRCASW6lLoeL2iopFNUpuGQFIBwKRJk8RisV6v9/X1JcvbiUZw/fr1DRs2GFqLWFK5u7v36tWLy+VasEsBgL29vRF5oZuJVaV5yrQ/ZSU5irpqg8Ogcej1eq1Wx2CY6UVSoStHo9K5+1u3JquseWhKqpePam+dl4b0sxc4sKx4RLkDwxaEBrIyVXW5JjmhKHalD4drjm5Go9FUVlYKhYb953ijVI9vyTPv1gyMccHIPMKjh8Nrs6d/7cWxNrlaBQUFH3744a+//mpQrcbNUtTqnt2rbkM6AQACg6a6XTtVZoZTcblcZ2dnQ2s1LlXRyzqEZq7EyoRB5MbOvFdlhhMJBIKffvrJ0FqNSyWXaJw9rbCwikwgCHgH8aVF5lgon5GRYWiVxqVS1mlVFrQZR8uRS1Q6nTmmb2bOnGno3BKx7qvaDt27dzc0+4hlDsGJjxH5DCmvwoe0tDRDV1hQUuHDkiVLDJ2xpaTChy5duhj66g4Vq/Bh5cqVhlahvAofMjIyDF20REmFD8uXLzf07R1KKnwIDAw09BUKKlbhw4oVKwytQnkVPmRnZ1OxihzExcUZmhiBTFJlZ2eNHBV5PeWfxY5arTY93VR7pZgad3d3S45VDAaDx+Mz6P/YvH7jt5mZj3/eexxvu4zhu+++M7SKSaTS6/VG79TeRIMeHl6HD/37kFulVGJ4CjNTXFwsFAqZTAM2ScdMqndnjvf2aufl1e7U6aNKpSLh2EUej5d2/87uPdtevHhmZ2cf2rlb7My5QqHoiy8/ys/PPXQwEa0Yf2ift1e7iIh+6J/T3x3boUPQhx98PHrMwNkfLHielZmSkuznFxA1dNR3674BgPXrtnft0mPtuuV/Jl8CgMgBXQHg8KFfXZxdAeDMryeOJ8RLJKXOzq4D3hoyYfxUYr5WvHDhwmXLlvn7+7e8CpZedfv2TYVSsXrlptq6Wh6Pd/fe34u//GjQwKjo0ROq5JUnTx1ZuGj2rh/j+/cbuG79ipcvX3h7twOAi0ln3d09Uamys7Nyc199+MHHaIPx8XtHjRq3ccNOOp0usLWb9f78n3b/8+wgZvJ7ZaUlRUUFXy5eAQBCexEA/LL/p4QT8WOiJ3p6+uTlvTp2/EB+Qe6SxQYPi82AQCDAcw6QzmB8tXS1ldU/T/q3bls/YviYj+Z/jv7ZtWvP6e+OvX3nZkREf8am1Sk3/vL2bvfgwb2CgryiooKSkmInJ+e/rl7mcXlduvSora0BgMDA4NiZc+vbD+kUVv9ZLPawtRWUV0iDgzujRySSskOH98UtXdWv7wD0iFDosGnzmnlzF9nwbTC8TEzYsWOHoVWwlKpDh6B6nYqLi3JyXhYU5J377XTDMqWlJTZ8m7DQbikpyTFT3ruQ9GvnkC7lFdILF3+dMX1W8l+XI3r3r+/Bw8K6t/zsd++majSaVavjVq3+JzMOum5OUlZKQKlqa2vZbLZB+ZawlMqK8+/KmYoKKQBMnzarb5+3GpaxtxcBQL9+A9dv+DY399Vff13+/LNl5VLJ8RPxfXpHNuz9AIDDMWApjrRcAgCrV212dHBqeNzVlYiJv2NjY/GMVQ3h8fgAoFQqPDwa2So3IqL/95tWr/lumZWVdZ/ekXWKut17t32/eTXa+7X8LA3Xm/L/5zqNnpFocLlcGs2wm1pT3QKLxR5OTs4XLv5aV1eHHtFoNPWPqG1tbMNCuz19+ihq6CgGg8Hn8SP7D378OL1h79csHI5Vebm0fjFJaGg3BEFOJx6rL1B/agKye/duPz8/g6qYSioEQebO+VQqlcydPyPxTMKpU0fnzptx5td/95zp128ggiDDh41B/xw5ciwA9O87sOWnCOkUVlUl/37T6qSkczduXBW7uY+JnnjjxtUlcZ+cv3DmYPzemGmjnz1/aoKLw4Da2lqtVmtQFRNOLPXpHblm1WYmg7l9x8YD8XucnFw6NRjC9Y7oHxHez9n5n7XWHQI6hoV2M6j3GzQoKnr0+OS/Lv20Z+ujxw8BYO6chR/O/vhldtamzWt+O3+6T+9IB5GjCa4MA2JjY7Oysgyq0vjrBX9fLFcqoHOkPXa2kYNzu/IGTnF0cDP5XfP777//+eefG9QHkmkO0JIwYp9wMs2sWxLEilUUTWBErKKkwgcj7quoWIUPVKwiDVSsIg1UrCINVKwiDVSsIg1UrCINVKwiDZjFKiaLRpQsgeaFb2/Aaq/WgFms4trbArSOAAAdI0lEQVTSpUUkXmVnNHnPauwczLFrIGaxSujK1pslfQOhqKnUin2tGSxzpMHBLFYJXVh8e8b95HKMDCMHV08Uhb4lMM+5jIhVTSWZSz5RptfTQvrZMdkWPvqoq9YmHyvqGSX0CCBuuqJmUjfevVyRfqMS9GBtrnyAetDrtLrW7J9rEHwhMy+zxsXbKjRSIPYzn05GrANsPiO0Xg9VFZpauZmybBYVFW3ZsqU1++caBIIgAgcm2/Q5AP/D5MmTsV8HiCBgY8+wsTeTVykAkatynb0My+xPOqg5QNJgIXOAfD4fbxNMjoXMAVZVmSPVJb5YwhwggiA+Pj54W2FyLCFW6fV6S91quyGWEKsQBHF3d8fbCpNjCbFKr9fn5eXhbYXJsYRY1UawhFiFIAiXy8XbCpNjCbFKr9fX1NTgbYXJsYRYRaPRvLxI8IZoK7GEWKXT6V69eoW3FSbHEmJVG8ESYhWNRvP19cXbCpNjCbFKp9MZ2omTEUuIVW0ES4hVbWRiyRJiVRuZWLKEWNVGsIRYhSCIoVt7khFLiFV6vV4qleJthcmxhFjVRrCEWIUgSH3+Rwtm2bJlL168MKgK4aTS6/VETg6HFTKZzNCk2YSLVW1kcZmFxKq2sLjMEmJVG8FC7quodYCNQrhYRa0DfBOE86o2QlVVFeljFYIgbm5ueFthcj744APSxyq9Xl9QUIC3FSbHxsbG0DczCRerEATx8PDA2wqTs3PnTkOrENGrcnNz8bbC5FhIrCLmjlPYYiGxSknm7d5aiIXEKkPvDcmIhcSq+h1ZLBhLiFUA4OrqircJJscSYhUAFBYW4m2CyTEiVjWfDcY8LFy4MDk5+fWnbXfv3sXJIsJBFK96//33XV1dkf+PBS9eJ3Gs6tChQ6dOnRq6OIvFmjZtGq5GmRByx6qpU6e6uLjU/+nh4TFs2DBcLTIh5L6vQh2rqKgIQRAWizV58mS8LTIhpL+viomJcXZ2BgBPT8+RI0fibY4JIXGsQgkMDAwNDWUwGFOmTMHbFtNiRKwyoANM+1NWnKNQ1elUChPOJgTy3xP1HlH33C1hU77pzmLrwGQwETcfK/9u+CxkM9V9VVWF5tDanE597Pn2TL4dU0f+ZNF0GiIpUtZVacry66LnuIE5kkC3lualkks1538pfnuam3myWpuZ7IfVrzLkoz4091RWVVWVtbW1QY7VfKz642hJv7HOFqkTAPh04rn4cm8nmTtNOfb3VdIiVW2Vlicg0Jgec8S+1k9um3s9L/b3VeXFKldf69ZZRXT49kxrPl2p0LE55hsPY39fpazTapSkH0Q0i1yi1qrMepmkv69qO5B7DrBNQe45wDYF6ecA2w5UrCINVKwiDVSsIg1UrCINVKwiDVSsIg1UrCINVKwiDW0xVj3Pyowc0PXmzWt4G2IYVKwiDRYbq/R6vaHJowiOEbEKe6kOH/kl8czxqiq5r6//jOkfdAnrDgBFxYU7dnx/914qi8Vu7xfw3ntzAvwDASA9/f7B+D3pGfcBIMC/4+zZH/u37wAAlZWy0WMGzv5gwfOszJSUZD+/gC2b9wDA+QtnTp0+mpv7isfjh/fqO/O9OehJX756cfT4gczMx2Kxx4L5XwQHd8b8urDFJGsrDCI9/f7uPds6dQpb+PESZyeXutpaAJBKJfM/ek9eVTlv7qIPZn2kVqsXfBz78uULACguLlSqlFNjYqdPm1VcXLj4y48UCkV9a/Hxe52dXDZu2Dl3zqcA8Mv+Xes3fOsu9vz0k6Xjx8UUFRUwmMx/Sh7aG9q528cLFqtUqqVfLayursb2ujDHtOsAW0JJaTEARI8a37Fjp0GDotCDB+P32AnsN67/kcFgAMCggVEx00afO396/txFAwcOrS/m7x+48NPZ6Rn3u3XtiR4JDAyOnTkX/VxWVhp/aN+gQVFLFq9Aj0ycMA0AigEAYMH8L95+ezgAeHp4z5k34+691H59B2B7adiCf6zqEtadz7dZvear+fM+69mzN3owNTWltKwkanif+mJqtbqstAR98/fa9T+PJ8Tn5Ly0trYGgIryfxPXhoV1r/98916qVqsdNWJso+e1sbFFP3h5tQOAsrISbK8Lc/CPVXZ29tu27Nv+4/dfLv04KCjk67g1Dg6O5RXSXr36zIqd37Akl8sDgAMH9/z8y853xkyaFTtfWi75ZsVinf7fpbsczr+ZUcvLpQDg4ODUtAHoK9+G3rKYH7VazWAwDBorYT9Y9/Dw+m7Nlo0bfnz5Muu7dcsBgM+3qayUeXh4NfwnFIqUSuXhIz8Pixo9b+6nwcGdAzsEN9Esj8cHgPIKC0kWPX369GfPnhlUBXupVCoVAISFduvZs8+z50/Rfiwj40Hmsyf1ZdDstApFnVKpbN++A3qwUi5Dt29ptNnQzl0B4Pz5xPojGo0Gc+OJDMYd4POszK++/nT0qPFWVtZ//30DHZFPnzbr1q3rn30+d/y4GDs7+7//vqHVaVeu2GhrK/Dx8T11+qi9vbCmunr/gZ9oNFp2duPjInd3z+HDos+eOyWXV3br1quyUnb27Mnvv9+Frf1m4+DBgzgPK1hMlqeH9+HDP+v1+pDOXT6a9zkAuLmKt23Z9+OuzYcO70MQxM8vIHr0BLT8V0tXf7du+YpvvxSLPT788JMXL56dPHnkg1kfNdr4Jx9/6ezseu7cqZQbfzmIHLt168Wgk+MW/nUM1an51wsyblQWvVT1HO7QOsOITsKGlxM/87C2MfjnM5p333136dKlBr2XTs0B4oMRueTJ2oGQnZ07d/J4PIOqUFLhg0AgMLQK1QHiw7x58wzNUElJhQ/FxcWGTqlQHSA+bNu2TSQSGVSFkgof0PQcBkF1gPjw/vvvSyQSg6pQUuFDXl6eoen9KKnwYd++ffb29gZVoWIVPhiR9JXyKnwYP358w1UkLaEZqRAEYTAtX04213wTtSg5OTnoSpOW04wMXFtGpdTCE9TrtCArU5lzWh0AkpKSMJbK3pmlNmWeMiIgK1O5t+ea+aTYzwHa2DNEbuzHN2WtsIro3E4qC400+IdrDTKZLCoqytBazcehyPEOlWXKx7csU60/Dhd17itwb2/WTaMVCgWXa7AftzTPevKJsrJ8JZNNsxGyNSrSd4nWfHpRdi2TTQvoxg/AKXujoRiQEr+qXCMtVtVUqk26ZYdUKj158uSsWbNMeA4AFotmI2Q6iNl4Jc/TarUGL6/QE4yXL1+OGTMGbytMS2pq6uzZsw2tZfn3TASktrbWiFhFTSzhQN++fXv37m1oLcJJhSCIEf/jyAWNRjNiOzUidoDoKyEWzO7duw8ePGhoLcJJRaPRiouL8bbCtJSWllpCrGIymVZWZr0hNT9ffPGFJXSAbDa7rKwMbytMi3FvoRNOKg6HY+iDHNIxevTokhKD36sknFRWVlaenp54W2FatFqtk1Mzr1++DuGkAoCSkhKZzDJnh1EuXrxoCR0gAHh7e1u2VMZBRKmYTKYRXTlZOHfu3LJly4yoSESpXF1di4qK8LbCVOTm5np4eBhRkXD3VQDg5+dH/HQuRjN79mzj8kUR0ascHR3v37+PtxWmwujUXkSUytfX19D8Q2RBrVZHREQYV5eIUrm7u7u4uKD5LyyMFy9eGPH4A4WIUqFYZB8YEBCwYcMG4+oSVKrOnTtbpFR5eXmVlZXG1SWoVN26dbPISdsZM2YY+q5OPQSVKiwsLCkpqaamBm9DsCQnJ6dbt25GrKtFMWBxmZn5+uuve/ToMWzYMLwNIQoE9SoAePvttx89eoS3FViSlZXVmn6CuFJFRET88ccfhr4wS1hKS0vnz5/fmhU+xJUKAMaMGXPq1Cm8rcCG7OzsTz/9tDUtEDdWAUBFRcXixYt37SJr0j9sIbRX2dnZeXt7nzhxAm9DWktBQcHu3btb2QihpQKA2NjY1l8k7uzatcuI97T/A3358uUY2WMSrK2tJRJJYWFhYGAg3rYYiUajodPpgwcPbmU7hI5VKBqNJiIiIjU1FW9DcIboHSAAMBiMhQsX7t27F29DjEGv10+cOBGTpkggFQBMmDDh7NmzeXl5eBtiMAcOHIiOjsakKRJ0gChpaWnbt2/fs2cP3obgBjm8CgBCQ0M7dep08eJFvA0xgPT09Pz8fMyaM80rlKaiT58+1dXVeFvRIh48eIA+8sAK0ngVyoYNG3744Qe8rWgRhYWFmzdvxrBBkknVvXt3JpN59OhRvA1pniFDhtja2mLYIMmkAoDPPvvsxo0bRB4N5uTkTJo0Cft2MexMzUZRUdGwYcPwtuKNLF++vKysDPNmSSmVXq9PSkraunVr/Z8jR47E0ZjRo0eb4Szk6wBRBg8eXFFRkZiYCACjRo3Kz8/fuHEjLpZs2bIlNzcXvc+9e/fu4cOHTXQiskoFAF999VViYmL//v0LCgr0ej1eC3LRzd3y8vIiIyMTExMnT55sohORWKopU6ZkZmaiLyLQaLTCwkJcFuSWlJSga9CrqqqSkpJiYmJMdCKySjV27NjMzEy1Wl1/RK1WZ2dnm9mMly9fNnxzWafTPX36dNy4caY4F1mlQhCEzWY3nMCUy+U5OTlmNuPVq1cNFyHp9Xo2m93wPxCGkFWqhISEhQsXtmvXjs1moztpKhQK84erZ8+eoQub9Xo9k8n09vb+5JNP0MEO5hDxVbgW8s4777zzzjvnzp07cOBAYWFhTU1NRkaGmW3IzMxEEzi4u7tPnDhx1KhRpjsX/g9BZKXqghd1NZWa2irj913Ozc3NzMxUqVRmXo2blJSEvt/RmgQO1nw615bh4s2xd2Y1UQxnqe4ny/KzFCwOzdHDSqMmfZ5V42AwaaV5dWqlzsmd3XWQ3ZuK4SnV09tVLx7W9B1r8PZAlsr1UyWeAdaBvRrPpYvbsKIwq+7RTTmlU0N6j3F6dr8q50lto9/iJtX9azL/blg+I7AM/LsKHl5rPL0KblLJpRqhCwevsxMWoStbXq5p9Cv8pCpXM63IeldnOlgcmlzS+B009WORBkoq0kBJRRooqUgDJRVpoKQiDZRUpIGSijRQUpEGSirSQElFGiipSAMlVauorq5+9vypec5FSdUqYmdNvHDhjHnORVapKitl8iq5qc/S7GoGc67nJdPisqSkc4eO/FxaWuzt1Q6h0ZydXL7+ag0AFBUX7tjx/d17qSwWu71fwHvvzQnwDwSAuK8/dRd7MhiMc7+d1qjVPXv2XvDRYh6Ph7Z25tcTxxPiJZJSZ2fXAW8NmTB+KpvNrqyUjR4zcPYHC55nZaakJPv5BWzZvOfCxV8TE49nv8yysrLu3q3XvLmLBAI7AJg4eXhFRXnimYTEMwlOTs5HD59DlyPu2bv9jysXVSqlu9hz/Pipb0W2NrkICmmkup6SvHbd8uHDont0jzh+Ij49/f68OZ8CgFQqmf/Re25u7vPmLkIQ5Pfff1vwcezOHQe9vdsBwPGE+LciB69etTk35+WG71cKhQ6zP1gAAL/s/ynhRPyY6Imenj55ea+OHT+QX5C7ZPEK9Fzx8XtHjRq3ccNOdOvex4/TPTy8Bg2KqqgoP3X6aE1tzZpVmwFg+bJ1n38xr3NIl3FjpzBZLHQh9NK4T4qLC6dMflcgsL9//863K5coFHVRQzFYH0gaqc6cSfDy8vl04VIACAjoOG7C0Fup1wMDgw/G77ET2G9c/yODwQCAQQOjYqaNPnf+9Py5iwBALPZY8uW3CIJ0COh49fqV23duzv5ggURSdujwvrilq/r1HYA2LhQ6bNq8Zt7cReifgYHBsTPn1p964SdL6pPYMxiM+EP7lEolm80O8A9kMBhCoSg4uDP67dVrVx6mpx05dFYkcgCAgQOG1NXVnjx1pG1JVVpWIhb/s5WGSOTA4XCqquQAkJqaUlpWEjW8T31JtVpdVvrP7i8cNqf+V3ZycsnIeAAAd++majSaVavjVq2OQ79CY5KkrFQoFAFAWFj3hqdWq9WnTh+9dPl8aWkxm83R6XQyWYWTUyNrrW7duq7RaCbHjKw/otVquVweJr8AaaRydRVnZj5WqVQsFis7O0uhUPj6+gNAeYW0V68+s2LnNyzc6K/DZDB1Oi0ASMslALB61WZHh/+335erq7imphoAOJx/N3vU6/VLln6c+ezx9GmzAgM7Xbt25eixAzp946tLKyqkQqHo+w07Gx6kM7D5kUkj1aQJ0xcumr1w0ewuYd0vXTof4B/49uDhAMDn21RWyjw8vFreFJ9vg35oSa0HD+7dvff30iUrBw4YAgAF+bn/KdBwlMjn28hkFU5OLmw2u+X2tBDSDNaDgkLeGTNJp9MVFuZPmDBt86bdaHAKC+uekfEg89mT+pJ1dXVNNxUa2g1BkNOJx1pSpVIuA4D2fgEN/0TfPQEAK46VVPpvdt2wsO5arfbXs//mmmzWmJZDGq9KOHEoLe32+PFTEQRhMBj5+bnt2vkBwPRps27duv7Z53PHj4uxs7P/++8bWp125Yqm3gsWu7mPiZ548tSRJXGf9I7oL5VKEs8cX7P6h3o9GhLYIZjFYu3es23YsOjs7OeHj/wMAC+zs9xcxQAQHBz6x5WLh4/8wufbdAzsNGhg1Nlzp3bu+qGouLC9X0BW1rPrKX/+su8Eh4PBikfSSOXfPjDhxKH6gQAAjBg+ZuEnS9xcxdu27Ptx1+ZDh/chCOLnFxA9ekKzrc2ds9DR0en06WO3b98UCkV9ekc6iBwbLeng4Bi3dNX2HRuXf/N5x8BO32/c9fMvO0+dPtq7d38A+GDWR+XlkoPxewS2dnPmLPTx8V3/3fbde7ZeuZJ07twpsdhj5IixDIxiFW6vF/y0JHvMAi82x4AeWKvVojc6KpVq1+4tiYnHky7cwOqHIAhajf7ImuwPN7R7/SvSXOfvv/+2Z9/2yP6DXVzcKiqk165d8fLysTCdmoY0l+rp5RMc1PnyHxfk8kqhUBQR3i9myky8jTIrpJHKv32Hr+JW420FnpBmsE5BSUUaKKlIAyUVaaCkIg2UVKSBkoo0UFKRBkoq0kBJRRpwk8rGjqmua6NJlZpApdDZiJiNfoWfVCKGtEjRgoJtC2mh0sa+8YlZ3KTq3FeQedvI3dwtmMzbsk59G9+OGzepXNtZdexl81dCCV4GEJCrJ0v8wvieAdaNfotzPsC0ZFneszq2Fd3Jw0qraaOhi86kleTWaZQ6J09214GEzAeIIpdo8l/UVle0KstmKzl//vyQIUNoNHz6GGs+nStguPlYCRwbH1Cg4C8VEejRo0dKSgrBH/9T91WkgZKKNFBSAQD4+fnhbULzUFIBADx//hxvE5qHkoo0UFKRBkoqAAA7O7v6N+YICyUVAEBFRQXx7y8pqQAAOnfuTHkVObh//z7lVRSYQUkFAMBisagOkByoVCqqAyQH7dq1o7yKHLx48YLyKgrMoKQCAOjUqRPVAZKDhw8fUh0gBWZQUgEAhIaGUh0gOUhLS6M6QArMoKQCamadTFAz6xRYQkkFAODv7091gOQgMzOT6gApMIOSijRQUpEGSioAgJCQEGpYQQ4ePHhADSsoMIOSCgCAx+NRHSA5qK6upjpAchAUFER5FTnIyMigvIocBAcHU15FDtLT0ymvIgeOjo7E96o2nWKkS5cuCPLvL4B+7tmz5/bt2/E2rRHatFc5OTmhCqGgR2bNmoW3XY3TpqUKDQ39zxF/f/+QkBCczGmGNi3VlClTUMdCEQqFU6dOxdWipmjTUgUGBnbu3BmNVXq9vmPHjmFhYXgb9UbatFQAEBMT4+LiAgAikSgmJgZvc5qirUvVoUOH4OBgvV4fFBREZJci01Zj9dTV6GpkmtoqTV2NVq3EIDHnW12nS19aD+wenXEDg1y6LDadbU3j2tC5NkwrPpaeQJr7qvIS9cv06mdpNXqEpqjW0Fl0JocJxDMeoSHqOrVGpeXwGKDV+oXyvIO4IlcWBi0TX6pKifrqaamiVq+nM3hCrrUA+42sTURdpbJKUgtaNZsNfaNFdk5N5TttFqJLdT1RmnmvysHH3saJi7ctxlNVVluWXe7bidd3jNDoRggt1cFVuQKxgO9IYpEaIi+tLc8pn/qlB51pzHwjQUeAaqV+2ydZDn4OFqMTANg4Wrt2dNr1Zbay1pjREBG9Sq3S//LNK7/eHngbYipe3Myf/LnYikc3qBYRverAtzleXV3xtsKEeHZxPbgqx9BahPOqC/tLdQwu156DtyGmpbZCqa2tGhHr1IKy/0Asr3qZUVNWqLZ4nQDA2o4tk+qep1W3vAqxpLp2Ruroa/xwllw4+dpfPyNteXkCSfU8rYontOLwWnWfSCJY1gxbZ+7T2/IWlieQVI9Tq5nWBO36VqwbfuLMWsybZfE4j25VtbAwgaTKy6zhOzS+dZOlwhNaFb+q02paNLIjilSvHtc6ePLwtgIHHL34rx7VtqQkUR6CSAuVQDPslrDlZGXfPX9pR2HxMz7P3te769BBH9rwRQAQt2rAOyO+yHiS/DgzxYrD69ktenBkLFpFq9VeTt57606iSlXXzqeLWm2qbSH1CF1SqGgX0vykDFG8qrpSw2CZ5P/N8xe3dx/4yMnRe/zopX3DJ2e/Stv581yV6p+f/uipb1yd28+ZuTMsZOjvV3Y/zkxBj58+t/5S8t6A9uHRwxexmJw6RUsjiqEw2IxqWYv2WCOKV1XJtAy2SZ5uJP62sWfX6Ojhi9A/2/v2WL9lQmbWreDA/gDQPWzkgH4zAMDVuf3fd888y7oV6B+RX/j01p3TA/q9O3TgbADoGjrsxct7prANAJhsenUlqaRCEITBxN7FyyuKSspeSsrzbt1JbHhcVvnPdpwslhX6gU6n29o4VsrLACD9cTIA9A2f1MA8U3U/NAYN6C2aaCeKVGwrRF6twXwWvapaCgCDImM7BUY2PM7ni14vTKMxdDotAMhkxRwOj2tti7U5jaCu07BZpJKKZ0svl2K/LaYVhw8AarXS0cGr5bW4XDuFolqtUTEZGDxobxq1UisStUgFogwr7BxZptg/1EHkIbB1vn3vrFJVhx7RajUajbrpWmK3AABIe5iEvUGvgdDAvmUP8okildjPqjy/pVMsLQdBkFFRn8irJFt3zUxJPXHt5rEtu2be+PtE07VCOg50dPA6eWbtrxd+uHv/wsmz6+RVZZjbhiIrkLv5WrWkJFGk4toyrPn0OrkK85aDA/u/F/M9nc789fymy8n77Oycfbz+u1T9P9Dp9Nipm9v79rh5++S5pK00hMa1bnyz8lairFEzWYitqEVeRaDnVXcuV+S8AKGHDd6GmI+KvCpXd32PoW/cYbshRBlWAEBYpF3q+awmpMp+lbbv0KLXj1tx+G+6RR3+9vyeXUdjZeGTzJRDJ75+/bherwfQNzqgf3/aD57uQW9qsDhLOny6dwvPTiCvAoDUi+W5L3QOPo3/L1Orlejg+z/o9fCmVw6trWw5HMxuAVQqRXVN+evHdTqdXq+n0xuZGOPzRW8aRkpeylzEEDGypc/niCUVABxen+8S6IzQiP66Z2vRQ2F60aTPxS1/r5Uow4p6Bk12eHm7AG8rTM6rO4VvjRcZ9P4x4aRycGOHD7MvSC/B2xATUvioLOwtG2dvw56jEq4DRMl9Wnc1USYOccTbEOwpyCjrPtjGL8Tgh6iE8yoUjwCrLgN4L/8uIOR/JGPRQ87dwk7hVkboRFyvQpEUqi4fKWVac4ReLbrzIDLSHJmqqu6tCQ5OHkY+6yG0VCipF8rvXC53DRBZCzhssq1nUtaoa2WK4mfSkL6CXsOErcljQgKpAECr0af9KXucWqVS6uxcbfQADDadxWEAAcf0Or1KodUoNQBQWVTFYEJAN35YpIDJbm2sIYdU9cil6vxndZJiVY1Mq1bpaqqwf27SSri2DAYDeLYMe2eW2M9K4IBZN0AyqdoyBB0BUrwOJRVpoKQiDZRUpIGSijRQUpGG/wOKS3OzDBIpNQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade\", grade)  # grade\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"rewrite\", rewrite)  # rewrite\n",
    "workflow.add_node(\"search\", search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"rewrite\": \"rewrite\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"rewrite\", \"search\")\n",
    "workflow.add_edge(\"search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c447a352-7c0b-4b9d-9477-7c32d97cb2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Output from node 'retrieve':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).')]}\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Output from node 'grade':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).'),\n",
      "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).')],\n",
      "  'web_search': False}\n",
      "---GENERATE---\n",
      "\"Output from node 'generate':\"\n",
      "{ 'generation': 'The types of agent memory are short-term memory and long-term '\n",
      "                'memory. Short-term memory involves in-context learning, while '\n",
      "                'long-term memory allows the agent to retain and recall '\n",
      "                'information over extended periods, often using an external '\n",
      "                'vector store for fast retrieval.'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef671b3b-2e6d-404c-98da-018566e05a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The types of agent memory are short-term memory and long-term memory. Short-term memory involves in-context learning, while long-term memory allows the agent to retain and recall information over extended periods, often using an external vector store for fast retrieval.\n"
     ]
    }
   ],
   "source": [
    "# Final generation\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a87d6af2-58fc-4e7d-b1df-b90bf267a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Output from node 'retrieve':\"\n",
      "{ 'documents': [ Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Effectiveness is measured by attack objective functions designed for different experiments:\\n- In text-to-image experiment, they used Q16 (Schramowski et al. 2022) and NudeNet (https://github.com/notAI-tech/NudeNet).\\n- text-to-text experiment: TOXIGEN\\nDiversity is measured by pairwise dissimilarity, in form of $\\\\sum_{(\\\\mathbf{x}_i, \\\\mathbf{x}_j) \\\\in \\\\text{All pairs}} [1 - \\\\text{sim}(\\\\mathbf{x}_i, \\\\mathbf{x}_j)]$\\nLow-toxicity is measured by Perspective API.\\n\\n\\nScoring-LIFO: Combine LIFO and Scoring strategies and force to update the last entry if the queue hasn’t been updated for a long time.'),\n",
      "                 Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Effectiveness is measured by attack objective functions designed for different experiments:\\n- In text-to-image experiment, they used Q16 (Schramowski et al. 2022) and NudeNet (https://github.com/notAI-tech/NudeNet).\\n- text-to-text experiment: TOXIGEN\\nDiversity is measured by pairwise dissimilarity, in form of $\\\\sum_{(\\\\mathbf{x}_i, \\\\mathbf{x}_j) \\\\in \\\\text{All pairs}} [1 - \\\\text{sim}(\\\\mathbf{x}_i, \\\\mathbf{x}_j)]$\\nLow-toxicity is measured by Perspective API.\\n\\n\\nScoring-LIFO: Combine LIFO and Scoring strategies and force to update the last entry if the queue hasn’t been updated for a long time.'),\n",
      "                 Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Effectiveness is measured by attack objective functions designed for different experiments:\\n- In text-to-image experiment, they used Q16 (Schramowski et al. 2022) and NudeNet (https://github.com/notAI-tech/NudeNet).\\n- text-to-text experiment: TOXIGEN\\nDiversity is measured by pairwise dissimilarity, in form of $\\\\sum_{(\\\\mathbf{x}_i, \\\\mathbf{x}_j) \\\\in \\\\text{All pairs}} [1 - \\\\text{sim}(\\\\mathbf{x}_i, \\\\mathbf{x}_j)]$\\nLow-toxicity is measured by Perspective API.\\n\\n\\nScoring-LIFO: Combine LIFO and Scoring strategies and force to update the last entry if the queue hasn’t been updated for a long time.'),\n",
      "                 Document(metadata={'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\"}, page_content='Effectiveness is measured by attack objective functions designed for different experiments:\\n- In text-to-image experiment, they used Q16 (Schramowski et al. 2022) and NudeNet (https://github.com/notAI-tech/NudeNet).\\n- text-to-text experiment: TOXIGEN\\nDiversity is measured by pairwise dissimilarity, in form of $\\\\sum_{(\\\\mathbf{x}_i, \\\\mathbf{x}_j) \\\\in \\\\text{All pairs}} [1 - \\\\text{sim}(\\\\mathbf{x}_i, \\\\mathbf{x}_j)]$\\nLow-toxicity is measured by Perspective API.\\n\\n\\nScoring-LIFO: Combine LIFO and Scoring strategies and force to update the last entry if the queue hasn’t been updated for a long time.')]}\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUESTION---\n",
      "\"Output from node 'grade':\"\n",
      "{'documents': [], 'web_search': True}\n",
      "---Rewrite---\n",
      "\"Output from node 'rewrite':\"\n",
      "{ 'question': 'What are the key concepts and findings of the AlphaCodium '\n",
      "              'research paper?'}\n",
      "---WEB SEARCH---\n",
      "\"Output from node 'search':\"\n",
      "{ 'documents': [ Document(metadata={}, page_content=\"cs arXiv:2401.08500 Help | Advanced Search arXiv identifier arXiv author ID Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that improves the performances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset called CodeContests, which includes competitive programming problems from platforms such as Codeforces. Subjects:   Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE) Cite as:    arXiv:2401.08500 [cs.LG] (or arXiv:2401.08500v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2401.08500 From: Tal Ridnik [view email] Access Paper: cs.LG cs References & Citations Bibliographic and Citation Tools Bibliographic Explorer Toggle Connected Papers Toggle Which authors of this paper are endorsers?\\n[AlphaCodium] Highest performance code generation method specialized for programming | AI-SCHOLAR | AI: (Artificial Intelligence) Articles and technical information media In other words, AlphaCodium, a unique code generation method, was able to improve LLM's performance in the programming area. Incidentally, AlphaCodium has succeeded in significantly improving code generation performance by using generic language models (GPT, DeepSeek, etc.) without additional training and applying dedicated flows. In other words, the pre-processing phase uses natural language processing to analyze the problem, generate and select initial candidate solution codes, and prepare test cases for use in the iteration phase. This experiment evaluates the extent to which AlphaCodium improves LLM code generation performance compared to the direct prompt input method. This article introduced research on AlphaCodium, a new code generation method specifically designed for competition programming problems.\\nNow Check Your EmailTo complete Subscribe, click the confirmation link in your inbox. CodiumAI has introduced AlphaCodium, a new code generation flow meant to improve the performance of pre-trained LLMs when solving code problems without fine-tuning. Unlike approaches to code problem-solving relying on costly, time-consuming, and data-hungry training phases to achieve their results, AlphaCodium favors the development of an iterative, test-based, multi-stage flow that results in improved performance with a reduced computational footprint. AlphaCodium was tested against a code generation dataset known as CodeContests, which consists of a selection of code generation problems sourced from platforms such as Codeforces. Perhaps the most notable departure from closed-source solutions such as AlphaCode is that AlphaCodium was released with reproducible code and an evaluation script, two features enabling reliable and reproducible future comparisons.\")]}\n",
      "---GENERATE---\n",
      "\"Output from node 'generate':\"\n",
      "{ 'generation': 'The AlphaCodium research paper introduces a new approach to '\n",
      "                'code generation using a test-based, multi-stage, '\n",
      "                'code-oriented iterative flow that enhances the performance of '\n",
      "                'large language models (LLMs) on code problems. It '\n",
      "                'significantly improves code generation performance without '\n",
      "                'additional training by using pre-trained LLMs and applying '\n",
      "                'dedicated flows. AlphaCodium was tested on the CodeContests '\n",
      "                'dataset and is notable for being released with reproducible '\n",
      "                'code and an evaluation script.'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"How does the AlphaCodium paper work?\"}\n",
    "\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7094c9a6-171d-4a89-9536-a35ef5c9eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AlphaCodium research paper introduces a new approach to code generation using a test-based, multi-stage, code-oriented iterative flow that enhances the performance of large language models (LLMs) on code problems. It significantly improves code generation performance without additional training by using pre-trained LLMs and applying dedicated flows. AlphaCodium was tested on the CodeContests dataset and is notable for being released with reproducible code and an evaluation script.\n"
     ]
    }
   ],
   "source": [
    "# Final generation\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf78476-f601-4ef5-b4b4-823073019994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
